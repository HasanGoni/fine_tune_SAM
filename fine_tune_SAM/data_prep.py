# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/02_data_preparation.ipynb.

# %% auto 0
__all__ = ['DPI', 'processor', 'get_dataset', 'show_dataset', 'get_bounding_box', 'SAMDataset']

# %% ../nbs/02_data_preparation.ipynb 2
from pathlib import Path
from typing import Union, List, Dict, Any, Optional, Callable, Type, Tuple
from fastcore.all import * 
from fastcore.test import *
import matplotlib.pyplot as plt
import numpy as np
import cv2
from PIL import Image
import matplotlib as mpl


# %% ../nbs/02_data_preparation.ipynb 3
DPI =mpl.rcParams['figure.dpi']
mpl.rcParams['image.cmap'] = 'gray'

# %% ../nbs/02_data_preparation.ipynb 4
import torch
from torch.utils.data import DataLoader
from datasets import Dataset
from torch.optim import AdamW
import monai

# %% ../nbs/02_data_preparation.ipynb 5
from transformers import SamProcessor
# we will start with base
processor = SamProcessor.from_pretrained('facebook/sam-vit-base')

# %% ../nbs/02_data_preparation.ipynb 7
def get_dataset(
        im_path:Union[Path,str],
        msk_path:Union[Path, str]
        ):
    "Create a dataset from image and mask path"

    # in case of it is string
    if isinstance(im_path, str):
        im_path = Path(im_path)
        msk_path = Path(msk_path)

    images = [Image.fromarray(cv2.imread(i.as_posix(),-1)) for i in im_path.ls(file_exts='.png')]
    print(f' image has {len(images)} images')
    masks = []
    for i in msk_path.ls(file_exts='.png'):
        msk = cv2.imread(i.as_posix(), -1)
        if msk.max() >1:
            if msk.shape[0]!= 256:
                print(msk.shape)
            msk_=Image.fromarray(msk)
            masks.append(msk_)

    print(f' masks has {len(masks)} images')
    dataset_dict = {
        'image':images,
        'label':masks
    }
    dataset = Dataset.from_dict(dataset_dict)
    return dataset

    

# %% ../nbs/02_data_preparation.ipynb 10
def show_dataset(dataset):
    idx = np.random.randint(0, len(dataset))
    print(f' dataset index will be visualized: {idx}')
    im_ = dataset[idx]['image']
    msk_ = dataset[idx]['label']
    fig, ax = plt.subplots(
        1, 2, figsize=(10, 5)
    )
    ax[0].imshow(im_)
    ax[1].imshow(msk_)


# %% ../nbs/02_data_preparation.ipynb 12
def get_bounding_box(
        ground_truth_map
        ):

    print(ground_truth_map.shape, type(ground_truth_map))

    y_, x_ = np.where(ground_truth_map> 0)
    x_min, x_max = np.min(x_), np.max(x_)
    y_min, y_max = np.min(y_), np.max(y_)

    # add perturbation to bounding box coordinates
    H, W = ground_truth_map.shape
    x_min = max(0, x_min - np.random.randint(0, 20))
    x_max = min(W, x_max + np.random.randint(0, 20))
    y_min = max(0, y_min - np.random.randint(0, 20))
    y_max = min(H, y_max + np.random.randint(0, 20))
    bbox = [x_min, y_min, x_max, y_max]

    return bbox

# %% ../nbs/02_data_preparation.ipynb 14
from torch.utils.data import Dataset


# %% ../nbs/02_data_preparation.ipynb 15
class SAMDataset(Dataset):
    "Creating dataset for SAM training"

    def __init__(
            self,
            dataset,
            processors
            ):
        self.dataset = dataset
        self.processors = processors

    def __len__(self):
        return len(self.dataset)

    def __getitem__(self, idx):
        item = self.dataset[idx]
        image = item['image']
        mask = np.array(item['label'])
        prompt = get_bounding_box(mask)

        # prepare image and prompt for model
        inputs = self.processors(
                                 image, 
                                 input_boxes=[[prompt]],
                                 return_tensors="pt"
                                 )
        # remove batch dimension created by the processor
        inputs = {k:v.squeeze(0) for k,v in inputs.items()}
        inputs['ground_truth_mask'] = mask
        return inputs
